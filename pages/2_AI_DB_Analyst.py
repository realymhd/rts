import streamlit as st
import pandas as pd
import sys
import os
import re
from pathlib import Path
from sqlalchemy import text

# í”„ë¡œì íŠ¸ ë£¨íŠ¸ ë””ë ‰í† ë¦¬ë¥¼ Python ê²½ë¡œì— ì¶”ê°€
sys.path.append(os.path.dirname(os.path.dirname(os.path.abspath(__file__))))

from src.db import get_db_engine
from src.utils import get_ai_response, load_prompt

st.set_page_config(layout="wide")

st.title("ğŸ’¡ AI DB ì• ë„ë¦¬ìŠ¤íŠ¸")
st.markdown("ë°ì´í„°ë² ì´ìŠ¤ ì „ì²´ êµ¬ì¡°ë¥¼ í•™ìŠµí•œ AIì—ê²Œ ìì—°ì–´ë¡œ ì§ˆë¬¸í•˜ì—¬ ë³µí•©ì ì¸ ë¶„ì„ì„ ìˆ˜í–‰í•˜ê³ , ìµœì¢… ë³´ê³ ì„œë§Œ ë°›ì•„ë³´ì„¸ìš”.")

@st.cache_data(ttl="1h")
def get_database_context(_engine):
    """ë°ì´í„°ë² ì´ìŠ¤ì˜ ëª¨ë“  í…Œì´ë¸” ìŠ¤í‚¤ë§ˆì™€ queries í´ë”ì˜ ì˜ˆì œ SQLì„ ê°€ì ¸ì˜µë‹ˆë‹¤."""
    if _engine is None:
        return ""
        
    context_parts = []
    
    # 1. ëª¨ë“  í…Œì´ë¸”ì˜ DDL (CREATE TABLE) ë¬¸ ê°€ì ¸ì˜¤ê¸°
    try:
        with _engine.connect() as connection:
            table_names = pd.read_sql(text("SHOW TABLES;"), connection).iloc[:, 0].tolist()
            
            context_parts.append("### ë°ì´í„°ë² ì´ìŠ¤ ìŠ¤í‚¤ë§ˆ (DDL)")
            for table_name in table_names:
                ddl_query = text(f"SHOW CREATE TABLE `{table_name}`;")
                ddl = pd.read_sql(ddl_query, connection).iloc[0, 1]
                context_parts.append(ddl)
    except Exception as e:
        st.warning(f"DB ìŠ¤í‚¤ë§ˆë¥¼ ê°€ì ¸ì˜¤ëŠ” ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}")

    # 2. queries í´ë”ì˜ ëª¨ë“  SQL íŒŒì¼ ë‚´ìš© ê°€ì ¸ì˜¤ê¸°
    try:
        query_files = list(Path("queries").rglob("*.sql"))
        if query_files:
            context_parts.append("\n### ëª¨ë²” SQL ì¿¼ë¦¬ ì˜ˆì‹œ")
            for file_path in query_files:
                context_parts.append(f"-- From: {file_path.name}\n{file_path.read_text()}")
    except Exception as e:
         st.warning(f"SQL ì˜ˆì‹œ íŒŒì¼ì„ ì½ëŠ” ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}")

    return "\n\n".join(context_parts)

def get_sql_from_ai_response(response_generator):
    """ìŠ¤íŠ¸ë¦¬ë° ì‘ë‹µì—ì„œ SQL ì¿¼ë¦¬ë§Œ ì¶”ì¶œí•©ë‹ˆë‹¤."""
    full_response = "".join(list(response_generator))
    
    # ë§ˆí¬ë‹¤ìš´ ì½”ë“œ ë¸”ë¡ì—ì„œ SQL ì¶”ì¶œ
    match = re.search(r"```sql\n(.*?)\n```", full_response, re.DOTALL)
    if match:
        return match.group(1).strip()
    else:
        # ì½”ë“œ ë¸”ë¡ì´ ì—†ëŠ” ê²½ìš°, ì „ì²´ ì‘ë‹µì„ SQLë¡œ ê°€ì •
        return full_response.strip()

# --- ë©”ì¸ í˜ì´ì§€ ---
engine = get_db_engine()

if engine:
    # DB ì»¨í…ìŠ¤íŠ¸ëŠ” ë°±ê·¸ë¼ìš´ë“œì—ì„œ ë¡œë”©
    if 'db_context' not in st.session_state:
        st.session_state['db_context'] = get_database_context(engine)
    db_context = st.session_state.get('db_context')

    st.subheader("ë¬´ì—‡ì´ ê¶ê¸ˆí•˜ì‹ ê°€ìš”?")
    user_question = st.text_input("ìì—°ì–´ë¡œ ì§ˆë¬¸ì„ ì…ë ¥í•˜ì„¸ìš” (ì˜ˆ: 'ì£¼ì°¨ë³„ ë¦¬í…ì…˜ì´ ê°€ì¥ ë†’ì€ ìœ ì € ê·¸ë£¹ì˜ íŠ¹ì§•ì€?')", key="user_question")

    if st.button("ğŸ“ˆ ë¶„ì„ ì‹¤í–‰", key="run_analysis") and user_question and db_context:
        generated_sql = ""
        df = pd.DataFrame()
        max_retries = 2

        with st.spinner("AIê°€ ì§ˆë¬¸ì„ ë¶„ì„í•˜ì—¬ SQL ì¿¼ë¦¬ë¥¼ ìƒì„±í•˜ëŠ” ì¤‘ì…ë‹ˆë‹¤..."):
            sql_prompt_template = load_prompt("prompts/db_analyst.txt")
            sql_prompt = sql_prompt_template.format(db_context=db_context, user_question=user_question)
            
            sql_response_generator = get_ai_response(sql_prompt)
            generated_sql = get_sql_from_ai_response(sql_response_generator)
        
        for attempt in range(max_retries):
            try:
                with st.spinner(f"ìƒì„±ëœ ì¿¼ë¦¬ ì‹¤í–‰ ì¤‘... (ì‹œë„ {attempt + 1}/{max_retries})"):
                    query = text(generated_sql)
                    df = pd.read_sql(query, engine)
                
                # ì„±ê³µ ì‹œ ë£¨í”„ íƒˆì¶œ
                break

            except Exception as e:
                error_message = str(e)
                if attempt < max_retries - 1:
                    with st.spinner(f"ì¿¼ë¦¬ ì˜¤ë¥˜ ë°œìƒ. AIê°€ ìŠ¤ìŠ¤ë¡œ ì½”ë“œë¥¼ ìˆ˜ì • í›„ ì¬ì‹œë„í•©ë‹ˆë‹¤..."):
                        corrector_prompt_template = load_prompt("prompts/sql_corrector.txt")
                        corrector_prompt = corrector_prompt_template.format(
                            user_question=user_question,
                            db_context=db_context,
                            faulty_sql=generated_sql,
                            error_message=error_message
                        )
                        correction_response_generator = get_ai_response(corrector_prompt)
                        generated_sql = get_sql_from_ai_response(correction_response_generator)
                else:
                    # ë§ˆì§€ë§‰ ì‹œë„ë„ ì‹¤íŒ¨í•˜ë©´ ìµœì¢… ì—ëŸ¬ ë©”ì‹œì§€ í‘œì‹œ
                    st.error(f"ë¶„ì„ ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {error_message}")
                    with st.expander("ì˜¤ë¥˜ê°€ ë°œìƒí•œ ìµœì¢… SQL ì¿¼ë¦¬ ë³´ê¸°"):
                        st.code(generated_sql, language='sql')
                    st.stop() # ë¶„ì„ ì¤‘ë‹¨

        # ìµœì¢… ë³´ê³ ì„œ ìƒì„±
        with st.spinner("AIê°€ ë¶„ì„ ê²°ê³¼ë¥¼ ë°”íƒ•ìœ¼ë¡œ ìµœì¢… ë³´ê³ ì„œë¥¼ ì‘ì„±í•˜ëŠ” ì¤‘ì…ë‹ˆë‹¤..."):
            report_prompt_template = load_prompt("prompts/final_analyst.txt")
            report_prompt = report_prompt_template.format(user_question=user_question, data_frame=df.to_markdown())
            
            report_generator = get_ai_response(report_prompt)
            
            st.subheader("ğŸ¤– AI ë¶„ì„ ë³´ê³ ì„œ")
            st.write_stream(report_generator)

else:
    st.warning("ë°ì´í„°ë² ì´ìŠ¤ì— ì—°ê²°í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤. `.streamlit/secrets.toml` ì„¤ì •ì„ í™•ì¸í•´ì£¼ì„¸ìš”.") 